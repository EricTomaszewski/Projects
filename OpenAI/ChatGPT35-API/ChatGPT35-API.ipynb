{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://platform.openai.com/docs/guides/chat\n",
    "\n",
    "https://platform.openai.com/docs/api-reference/introduction\n",
    "\n",
    "https://platform.openai.com/playground?mode=chat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usage: openai api [-h]\n",
    "                  {engines.list,engines.get,engines.update,engines.generate,chat_completions.create,completions.create,deployments.list,deployments.get,deployments.delete,deployments.create,models.list,models.get,models.delete,files.create,files.get,files.delete,files.list,fine_tunes.list,fine_tunes.create,fine_tunes.get,fine_tunes.results,fine_tunes.events,fine_tunes.follow,fine_tunes.cancel,fine_tunes.delete,image.create,image.create_edit,image.create_variation,audio.transcribe,audio.translate}\n",
    "                  ...\n",
    "\n",
    "positional arguments:\n",
    "  {engines.list,engines.get,engines.update,engines.generate,chat_completions.create,completions.create,deployments.list,deployments.get,deployments.delete,deployments.create,models.list,models.get,models.delete,files.create,files.get,files.delete,files.list,fine_tunes.list,fine_tunes.create,fine_tunes.get,fine_tunes.results,fine_tunes.events,fine_tunes.follow,fine_tunes.cancel,fine_tunes.delete,image.create,image.create_edit,image.create_variation,audio.transcribe,audio.translate} \n",
    "                        All API subcommands\n",
    "\n",
    "options:\n",
    "  -h, --help            show this help message and exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\irene\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.26.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\irene\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\irene\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\irene\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\irene\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\irene\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\irene\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\irene\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\irene\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\irene\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\irene\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\irene\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\irene\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\irene\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\irene\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# for venv - in terminal:\n",
    "# pip install openai\n",
    "# pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahoy mateys! Let me tell ye about the ChatGPT API, \n",
      " arrr! This be the treasure ye be searchin' for, me \n",
      " hearties. It be a treasure trove of chatbot goodies that'll \n",
      " make ye web or software shine like the gold of \n",
      " Ol' Blackbeard himself. With the ChatGPT API, ye can create, \n",
      " develop, and customize ye chatbots like never before! The API \n",
      " be easy to use and be designed for developers, savvy \n",
      " or not. Ye can integrate ye chatbot into ye website \n",
      " or mobile app with ease, making ye site or app \n",
      " stand out from the rest of the crew. The ChatGPT \n",
      " API be perfect for businesses who want to improve customer \n",
      " service as well as for individual developers who want to \n",
      " create a chatbot for personal use. It can be integrated \n",
      " with several messaging apps and platforms like WhatsApp, Facebook Messenger, \n",
      " and more. Plus, ye can customize ye chatbot with personalized \n",
      " messages and responses, setting ye apart from the rest of \n",
      " the scallywags. So what are ye waiting for, me hearties? \n",
      " Set your sails and set a course for the ChatGPT \n",
      " API. Ye won't regret it! Arrr! "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# HOW TO SET API KEY VARIABLE IN THE SYSTEM?\n",
    "# https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\n",
    "# setx OPENAI_API_KEY “<yourkey>”\n",
    "# echo %OPENAI_API_KEY%\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
    "# ROLES AVAILABLE:\n",
    "# 1) system - to set the behaviour of the assistant\n",
    "# 2) user - the one who gives the instructions\n",
    "# 3) assistant - to store prior responses\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \n",
    "         \"content\": \"Tell the world about the ChatGPT API in the style of a pirate.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "'''\n",
    "messages = [\n",
    "    {\"role\": \"system\",\n",
    "    \"content\": \"You're a kind helpful assistant\"}\n",
    "]\n",
    "'''\n",
    "\n",
    "# ALL TEXT AT ONCE\n",
    "print(completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################\n",
    "# TEXT ONE WORD AT A TIME\n",
    "'''\n",
    "text = completion.choices[0].message.content\n",
    "\n",
    "\n",
    "import time\n",
    "def word_at_a_time(text):\n",
    "    words = text.split()\n",
    "    i = 0\n",
    "    for word in words:\n",
    "        print(word, end=\" \", flush=True)\n",
    "        time.sleep(0.3)\n",
    "        print(\"\\b\", end=\" \", flush=True)\n",
    "        i += 1\n",
    "        if i == 10:\n",
    "            print(\"\\n\", end=\" \", flush=True)\n",
    "            i = 0\n",
    "        \n",
    "word_at_a_time(text)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your_api_key_here\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('api.ini')\n",
    "\n",
    "api_key = config['API_KEY']['key']\n",
    "print(api_key)\n",
    "\n",
    "\n",
    "# in api.ini\n",
    "# [API_KEY]\n",
    "# key = your_api_key_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2020 World Series was played at Globe Life Field in Arlington, Texas due to the COVID-19 pandemic.\n",
      "\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"The 2020 World Series was played at Globe Life Field in Arlington, Texas due to the COVID-19 pandemic.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1679244701,\n",
      "  \"id\": \"chatcmpl-6vqXt2XJQtr17f2gG5duywB7zmaEx\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 25,\n",
      "    \"prompt_tokens\": 56,\n",
      "    \"total_tokens\": 81\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Note: you need to be using OpenAI Python v0.27.0 for the code below to work\n",
    "import openai\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(completion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DaVinci model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "\n",
      "# pirate-yay [message] pirate-yay ' Yo ho! Tell your friends about the ChatGPT API in the style of a pirate! '\n",
      "\n",
      "Example:\n",
      "\n",
      "$ pirate-yay ' Yo ho! Tell your friends about the ChatGPT API in the style of a pirate! ' Yo ho! Tell your friends about the ChatGPT API in the style of a pirate!\n",
      "\n",
      "Contributing\n",
      "\n",
      "For a quick start, check out our Code of Conduct.\n",
      "\n",
      "Don't hesitate to open an issue if you find any problems.\n",
      "\n",
      "For more information on how to contribute, check out our contributing guide.\n",
      "\n",
      "License\n",
      "\n",
      "MIT © 2017 hackr.io\n"
     ]
    }
   ],
   "source": [
    "# The same API key but working with the DaVinci model\n",
    "\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Set the OpenAI API key using an environment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",

    "\n",
    "# Use the GPT-3 \"davinci\" model to generate text\n",
    "model_engine = \"davinci\"\n",
    "# below line is the difference between davinci and 3.5\n",
    "# InvalidRequestError: This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?\n",
    "\n",
    "# Prompt the model with a pirate-style description of the ChatGPT API\n",
    "prompt = \"Tell the world about the ChatGPT API in the style of a pirate.\"\n",
    "\n",
    "# Generate a completion using the OpenAI API\n",
    "completion = openai.Completion.create(\n",
    "    engine=model_engine,\n",
    "    prompt=prompt,\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")\n",
    "\n",
    "# Print the generated text\n",
    "print(completion.choices[0].text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'files': 'BpeTrainer' object cannot be converted to 'Sequence'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m tokenizer\u001b[39m.\u001b[39mpre_tokenizer \u001b[39m=\u001b[39m Whitespace()\n\u001b[0;32m      9\u001b[0m trainer \u001b[39m=\u001b[39m BpeTrainer(vocab_size\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m, min_frequency\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m tokenizer\u001b[39m.\u001b[39;49mtrain(trainer, [\u001b[39m\"\u001b[39;49m\u001b[39mpath/to/corpus.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcount_tokens\u001b[39m(prompt):\n\u001b[0;32m     13\u001b[0m     \u001b[39m# Tokenize the prompt with the trained tokenizer\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     encoding \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(prompt)\n",
      "\u001b[1;31mTypeError\u001b[0m: argument 'files': 'BpeTrainer' object cannot be converted to 'Sequence'"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "# Define a BPE tokenizer and train it on your corpus\n",
    "tokenizer = Tokenizer(BPE())\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(vocab_size=10000, min_frequency=2)\n",
    "tokenizer.train(trainer, [\"corpus.txt\"])\n",
    "\n",
    "def count_tokens(prompt):\n",
    "    # Tokenize the prompt with the trained tokenizer\n",
    "    encoding = tokenizer.encode(prompt)\n",
    "    num_tokens = len(encoding.tokens)\n",
    "\n",
    "    return num_tokens\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Hello, how are you today?\"\n",
    "num_tokens = count_tokens(prompt)\n",
    "print(f\"Number of tokens in prompt: {num_tokens}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
